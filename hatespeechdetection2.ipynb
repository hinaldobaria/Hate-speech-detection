{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-08T05:39:17.587475Z","iopub.status.busy":"2024-10-08T05:39:17.586804Z","iopub.status.idle":"2024-10-08T05:39:18.100690Z","shell.execute_reply":"2024-10-08T05:39:18.099450Z","shell.execute_reply.started":"2024-10-08T05:39:17.587416Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/hate-speech-and-offensive-language-dataset/labeled_data.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T05:39:20.855869Z","iopub.status.busy":"2024-10-08T05:39:20.855220Z","iopub.status.idle":"2024-10-08T05:39:25.466969Z","shell.execute_reply":"2024-10-08T05:39:25.465375Z","shell.execute_reply.started":"2024-10-08T05:39:20.855819Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","import pandas as pd # Import the pandas library"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T05:39:28.029361Z","iopub.status.busy":"2024-10-08T05:39:28.028506Z","iopub.status.idle":"2024-10-08T05:39:28.085666Z","shell.execute_reply":"2024-10-08T05:39:28.084396Z","shell.execute_reply.started":"2024-10-08T05:39:28.029272Z"},"trusted":true},"outputs":[],"source":["from imblearn.over_sampling import SMOTE\n","import re # Import the regex library"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T05:39:30.334677Z","iopub.status.busy":"2024-10-08T05:39:30.333896Z","iopub.status.idle":"2024-10-08T05:39:30.419166Z","shell.execute_reply":"2024-10-08T05:39:30.417644Z","shell.execute_reply.started":"2024-10-08T05:39:30.334625Z"},"trusted":true},"outputs":[],"source":["# Load the dataset (replace 'your_dataset.csv' with the actual file name)\n","data = pd.read_csv('/kaggle/input/hate-speech-and-offensive-language-dataset/labeled_data.csv') \n","# Load data into the 'data' variable"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T05:40:12.337529Z","iopub.status.busy":"2024-10-08T05:40:12.337037Z","iopub.status.idle":"2024-10-08T05:40:12.359032Z","shell.execute_reply":"2024-10-08T05:40:12.357745Z","shell.execute_reply.started":"2024-10-08T05:40:12.337482Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>count</th>\n","      <th>hate_speech</th>\n","      <th>offensive_language</th>\n","      <th>neither</th>\n","      <th>class</th>\n","      <th>tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>rt  mayasolovely  as a woman you shouldn t...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>rt  mleew17  boy dats cold   tyga dwn ba...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>rt  urkindofbrand dawg     rt  80sbaby...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>rt  c_g_anderson   viva_based she lo...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>rt  shenikaroberts  the shit you...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n","0           0      3            0                   0        3      2   \n","1           1      3            0                   3        0      1   \n","2           2      3            0                   3        0      1   \n","3           3      3            0                   2        1      1   \n","4           4      6            0                   6        0      1   \n","\n","                                               tweet  \n","0      rt  mayasolovely  as a woman you shouldn t...  \n","1        rt  mleew17  boy dats cold   tyga dwn ba...  \n","2          rt  urkindofbrand dawg     rt  80sbaby...  \n","3            rt  c_g_anderson   viva_based she lo...  \n","4                rt  shenikaroberts  the shit you...  "]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T05:39:32.669719Z","iopub.status.busy":"2024-10-08T05:39:32.669205Z","iopub.status.idle":"2024-10-08T05:39:32.676944Z","shell.execute_reply":"2024-10-08T05:39:32.675667Z","shell.execute_reply.started":"2024-10-08T05:39:32.669670Z"},"trusted":true},"outputs":[],"source":["# Text Preprocessing: Lowercase conversion, remove special characters, etc.\n","def preprocess_text(text):\n","    text = text.lower() # convert to lowercase\n","    text = re.sub(r'\\W', ' ', text) # remove special characters\n","    return text"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T05:39:35.461495Z","iopub.status.busy":"2024-10-08T05:39:35.460916Z","iopub.status.idle":"2024-10-08T05:39:35.753480Z","shell.execute_reply":"2024-10-08T05:39:35.751891Z","shell.execute_reply.started":"2024-10-08T05:39:35.461444Z"},"trusted":true},"outputs":[],"source":["data['tweet'] = data['tweet'].apply(preprocess_text)\n","\n","# Prepare the data for classification\n","X = data['tweet']\n","y = data['class']"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T05:39:46.779837Z","iopub.status.busy":"2024-10-08T05:39:46.779364Z","iopub.status.idle":"2024-10-08T05:39:46.789754Z","shell.execute_reply":"2024-10-08T05:39:46.788344Z","shell.execute_reply.started":"2024-10-08T05:39:46.779791Z"},"trusted":true},"outputs":[{"data":{"text/plain":["24783"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["X.size"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T05:39:50.991833Z","iopub.status.busy":"2024-10-08T05:39:50.989587Z","iopub.status.idle":"2024-10-08T05:39:51.003509Z","shell.execute_reply":"2024-10-08T05:39:51.002282Z","shell.execute_reply.started":"2024-10-08T05:39:50.991757Z"},"trusted":true},"outputs":[],"source":["# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T05:39:55.343759Z","iopub.status.busy":"2024-10-08T05:39:55.343268Z","iopub.status.idle":"2024-10-08T05:39:57.629955Z","shell.execute_reply":"2024-10-08T05:39:57.628579Z","shell.execute_reply.started":"2024-10-08T05:39:55.343714Z"},"trusted":true},"outputs":[],"source":["# Vectorize the tweet data for SVM and Random Forest using TF-IDF with bigrams\n","tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n","X_train_tfidf = tfidf.fit_transform(X_train)\n","X_test_tfidf = tfidf.transform(X_test)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T05:40:31.277848Z","iopub.status.busy":"2024-10-08T05:40:31.276097Z","iopub.status.idle":"2024-10-08T05:40:33.284084Z","shell.execute_reply":"2024-10-08T05:40:33.282690Z","shell.execute_reply.started":"2024-10-08T05:40:31.277768Z"},"trusted":true},"outputs":[],"source":["# Address Class Imbalance using SMOTE (Apply SMOTE after TF-IDF)\n","smote = SMOTE(random_state=42)\n","X_train_resampled, y_train_resampled = smote.fit_resample(X_train_tfidf, y_train)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T05:40:52.709025Z","iopub.status.busy":"2024-10-08T05:40:52.708500Z","iopub.status.idle":"2024-10-08T05:40:52.720765Z","shell.execute_reply":"2024-10-08T05:40:52.719433Z","shell.execute_reply.started":"2024-10-08T05:40:52.708967Z"},"trusted":true},"outputs":[{"data":{"text/plain":["702793"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["X_train_resampled.size"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T05:41:32.909376Z","iopub.status.busy":"2024-10-08T05:41:32.908712Z","iopub.status.idle":"2024-10-08T05:43:45.402744Z","shell.execute_reply":"2024-10-08T05:43:45.400821Z","shell.execute_reply.started":"2024-10-08T05:41:32.909291Z"},"trusted":true},"outputs":[],"source":["# Define the SVM model\n","svm_model = SVC()\n","svm_model.fit(X_train_tfidf, y_train)\n","# Evaluate both models on the test set\n","svm_predictions = svm_model.predict(X_test_tfidf)\n","# Classification report for SVM\n","svm_report = classification_report(y_test, svm_predictions)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T05:43:54.891881Z","iopub.status.busy":"2024-10-08T05:43:54.891406Z","iopub.status.idle":"2024-10-08T05:43:54.898602Z","shell.execute_reply":"2024-10-08T05:43:54.897244Z","shell.execute_reply.started":"2024-10-08T05:43:54.891833Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      0.10      0.17       290\n","           1       0.90      0.97      0.94      3832\n","           2       0.85      0.80      0.82       835\n","\n","    accuracy                           0.89      4957\n","   macro avg       0.79      0.62      0.64      4957\n","weighted avg       0.88      0.89      0.87      4957\n","\n"]}],"source":["print(svm_report)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T05:44:24.775751Z","iopub.status.busy":"2024-10-08T05:44:24.775219Z","iopub.status.idle":"2024-10-08T05:44:44.240878Z","shell.execute_reply":"2024-10-08T05:44:44.239347Z","shell.execute_reply.started":"2024-10-08T05:44:24.775703Z"},"trusted":true},"outputs":[],"source":["# Define the Random Forest model\n","rf_model = RandomForestClassifier()\n","rf_model.fit(X_train_tfidf, y_train)\n","rf_predictions = rf_model.predict(X_test_tfidf)\n","# Classification report for Random Forest\n","rf_report = classification_report(y_test, rf_predictions)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T05:46:13.228902Z","iopub.status.busy":"2024-10-08T05:46:13.228381Z","iopub.status.idle":"2024-10-08T05:46:13.235535Z","shell.execute_reply":"2024-10-08T05:46:13.234277Z","shell.execute_reply.started":"2024-10-08T05:46:13.228852Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.45      0.10      0.16       290\n","           1       0.90      0.97      0.93      3832\n","           2       0.85      0.77      0.81       835\n","\n","    accuracy                           0.88      4957\n","   macro avg       0.73      0.61      0.63      4957\n","weighted avg       0.86      0.88      0.87      4957\n","\n"]}],"source":["print(rf_report)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T05:46:29.091899Z","iopub.status.busy":"2024-10-08T05:46:29.091463Z","iopub.status.idle":"2024-10-08T05:46:30.986380Z","shell.execute_reply":"2024-10-08T05:46:30.984888Z","shell.execute_reply.started":"2024-10-08T05:46:29.091857Z"},"trusted":true},"outputs":[],"source":["# Now let's prepare the data for the LSTM model\n","max_words = 10000\n","max_len = 100\n","\n","# Tokenizing and padding for LSTM\n","tokenizer = Tokenizer(num_words=max_words)\n","tokenizer.fit_on_texts(X_train)\n","X_train_seq = tokenizer.texts_to_sequences(X_train)\n","X_test_seq = tokenizer.texts_to_sequences(X_test)\n","\n","X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n","X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T05:46:45.183412Z","iopub.status.busy":"2024-10-08T05:46:45.182834Z","iopub.status.idle":"2024-10-08T05:53:45.180520Z","shell.execute_reply":"2024-10-08T05:53:45.179231Z","shell.execute_reply.started":"2024-10-08T05:46:45.183320Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 263ms/step - accuracy: 0.8195 - loss: 0.5284 - val_accuracy: 0.9022 - val_loss: 0.2957\n","Epoch 2/5\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 260ms/step - accuracy: 0.9191 - loss: 0.2499 - val_accuracy: 0.9038 - val_loss: 0.2769\n","Epoch 3/5\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 264ms/step - accuracy: 0.9400 - loss: 0.1751 - val_accuracy: 0.8967 - val_loss: 0.3082\n","Epoch 4/5\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 250ms/step - accuracy: 0.9589 - loss: 0.1181 - val_accuracy: 0.8931 - val_loss: 0.4087\n","Epoch 5/5\n","\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 252ms/step - accuracy: 0.9732 - loss: 0.0785 - val_accuracy: 0.8648 - val_loss: 0.4951\n","\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.8594 - loss: 0.5248\n"]}],"source":["# Define a deeper LSTM model\n","lstm_model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(input_dim=max_words, output_dim=128, input_length=max_len),\n","    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n","    tf.keras.layers.GlobalMaxPooling1D(),\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    tf.keras.layers.Dropout(0.5), # Adding dropout for regularization\n","    tf.keras.layers.Dense(3, activation='softmax')\n","])\n","\n","lstm_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Train the LSTM model\n","lstm_model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_data=(X_test_pad, y_test))\n","\n","# Evaluate the LSTM model\n","lstm_loss, lstm_accuracy = lstm_model.evaluate(X_test_pad, y_test)\n"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-10-08T05:54:28.217214Z","iopub.status.busy":"2024-10-08T05:54:28.216734Z","iopub.status.idle":"2024-10-08T05:54:28.224630Z","shell.execute_reply":"2024-10-08T05:54:28.223367Z","shell.execute_reply.started":"2024-10-08T05:54:28.217168Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["SVM Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.60      0.10      0.17       290\n","           1       0.90      0.97      0.94      3832\n","           2       0.85      0.80      0.82       835\n","\n","    accuracy                           0.89      4957\n","   macro avg       0.79      0.62      0.64      4957\n","weighted avg       0.88      0.89      0.87      4957\n","\n","Random Forest Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.45      0.10      0.16       290\n","           1       0.90      0.97      0.93      3832\n","           2       0.85      0.77      0.81       835\n","\n","    accuracy                           0.88      4957\n","   macro avg       0.73      0.61      0.63      4957\n","weighted avg       0.86      0.88      0.87      4957\n","\n","LSTM Accuracy:  0.8648375868797302\n"]}],"source":["# Generate classification reports for SVM, Random Forest, and LSTM\n","print(\"SVM Report:\\n\", svm_report)\n","print(\"Random Forest Report:\\n\", rf_report)\n","print(\"LSTM Accuracy: \", lstm_accuracy)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":723100,"sourceId":1257215,"sourceType":"datasetVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
